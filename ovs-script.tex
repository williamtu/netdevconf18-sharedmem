\section{Scripts} \label{sec:bash_script}

\begin{lstlisting}[language=sh, caption={SF-representor setup on BlueField}, label={lst:sf}]
#!/bin/bash
#ethtool --set-priv-flags p0 rx_striding_rq off
for i in {100..200}; do
    devlink port add pci/0000:08:00.0 flavour pcisf pfnum 0 sfnum $i
done
for i in {100..200}; do
    ethtool -L $dev combined 1
    ethtool -G $dev rx 1024
    ip link set dev $dev up
done	
#optional: create SF
# devlink port function set $dev state active
# devlink dev param set auxiliary/mlx5_core.sf.$i name enable_eth value 1 cmode driverinit
# devlink dev reload auxiliary/mlx5_core.sf.$i
\end{lstlisting}

\begin{lstlisting}[language=sh, caption={Collect page\_pool usage on BlueField}, label={lst:bash_script}]
$ ./tools/net/ynl/cli.py --spec Documentation/netlink/specs/netdev.yaml  --dump page-pool-get
[{'id': 673,
  'ifindex': 120,
  'inflight': 512, // 512 pages used for 1024 RXQ depth
  'inflight-mem': 2097152, // about 2MB
  'napi-id': 1179}, // each RXQ has its own NAPI-ID
 {'id': 674,
  'ifindex': 122,
  'inflight': 512,
  'inflight-mem': 2097152,
  'napi-id': 1180},
  ...
\end{lstlisting}

\begin{lstlisting}[language=sh, caption={Apache ab and iperf3 test}, label={lst:ab}]
# 1 million requests with 100 concurrency
$ ab -c100 -l -n 1000000 -k -l http://10.1.1.1/
# single TCP connection bandwidth
$ iperf3 -t20 -i2 -c 10.1.1.1
\end{lstlisting}

\begin{lstlisting}[language=sh, caption={DPDK-pktgen consumes all RXQ}, label={lst:fairness}]
#!/bin/bash
# similar setup for Linux bridge, but disable HW offload by setting aging=0
PF1=eth2
VFREP1=eth4
VFREP2=eth5
VF1=eth6
VF2=eth7
NS1=ns1
NS2=ns2
setup_dev_ns()
{
        ns=$1
        vfdev=$2
        ip=$3
        ip netns del $ns || true
        ip netns add $ns
        ip link set dev $vfdev netns $ns
        ip netns exec $ns ifconfig $vfdev ${ip}/24 up
}
test_dpdk()
{
    ip netns exec $NS1 bash
    echo 1280 > /sys/devices/system/node/node0/hugepages/hugepages-2048kB/nr_hugepages
    dpdk-testpmd -l 0-3 --socket-mem=512  -a 0000:08:00.2 -- -i --nb-cores=1 --forward-mode=txonly \
--eth-peer=0,b8:3f:d2:ba:65:9e --txpkts=64 --txq=1 --rxq=1 --stats-period=1 --txonly-multi-flow \
--total-num-mbufs=2048
        exit

}
setup_ovs()
{
        echo 2 > /sys/class/net/$PF1/device/sriov_numvfs
        ovs-vsctl set Open_vSwitch . other_config:hw-offload=false 
        /usr/share/openvswitch/scripts/ovs-ctl restart
        ovs-vsctl add-br ovsbr0
        ovs-vsctl add-port ovsbr0 $PF1
        ovs-vsctl add-port ovsbr0 $VFREP1
        ovs-vsctl add-port ovsbr0 $VFREP2
        ip link set dev $PF1 up
        ip link set dev $VFREP1 up
        ip link set dev $VFREP2 up
        setup_dev_ns $NS1 $VF1 192.167.111.1
        setup_dev_ns $NS2 $VF2 192.167.111.2
        ip netns exec $NS1 ping -i .05 -c10 192.167.111.2
        ip netns exec $NS2 ping -i .05 -c10 192.167.111.1
}
devlink dev eswitch set pci/0000:08:00.0 mode switchdev
setup_ovs
test_dpdk
\end{lstlisting}
